{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TODO\n",
    " - make seasonnal function (juste pour le bo geste)\n",
    " - validation pour choisir juste la meilleur category et pas les n'th meilleures\n",
    " - sortir les id de category et pas le y0 avec la correlation\n",
    " - faire corelation solo\n",
    " - nettoyer le code pour improvement overall\n",
    " - nettoyer le code pour improvement shift\n",
    " \n",
    " \n",
    " \n",
    "# ToC\n",
    "\n",
    " - 0. Importing librairies\n",
    " \n",
    " - 1. Preprocessing all the data\n",
    "    - 1.1. Birth data\n",
    "    - 1.2. Google Trend Data\n",
    "        - 1.2.1. Find all Google Trend Data categories\n",
    "        - 1.2.2. Extracting all Google Trend Data for each categories\n",
    "        \n",
    "- 2. Category Selection\n",
    "    - 2.0. Mini preprocessing\n",
    "    - 2.0.0. Rolling window validation\n",
    "    - 2.1. By correlation overall\n",
    "        - 2.1.1. Algorithm\n",
    "        - 2.1.2. Parameter validation\n",
    "        - 2.1.3. Run\n",
    "    - 2.2. By correlation with rolling window\n",
    "        - 2.2.1. Algorithm\n",
    "        - 2.2.2. Parameter validation\n",
    "        - 2.2.3. Run\n",
    "    - 2.3. By improvement overall\n",
    "        - 2.3.1. Algorithm\n",
    "        - 2.3.2. Parameter validation\n",
    "        - 2.3.3. Run\n",
    "    - 2.4. By improvement with rolling window\n",
    "        - 2.4.1. Algorithm\n",
    "        - 2.4.2. Parameter validation\n",
    "            - 2.4.2.1. Months shifting\n",
    "            - 2.4.2.2. Number of best category\n",
    "        - 2.4.3. Run\n",
    "    - 2.5. Final Algorithm selection\n",
    "        - 2.5.1. Selection\n",
    "        - 2.5.2. Final category selection\n",
    "    \n",
    "    \n",
    "- 3. Prediction and visualization\n",
    "    - 3.1. Prediction\n",
    "    - 3.2. Prediction plotting\n",
    "    - 3.3. Visualisation of categories"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0. Importing librairies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing librairies\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "from dateutil.relativedelta import relativedelta\n",
    "from statsmodels.regression.rolling import RollingOLS\n",
    "\n",
    "# External librairies\n",
    "# Google trend unofficial API\n",
    "from pytrends.request import TrendReq"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Preprocessing all the data\n",
    "## 1.1 Birth data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Folder with all the csv to export/import\n",
    "data_folder = './Data/'\n",
    "\n",
    "# Importing birth data with selecting correct columns and changing columns names\n",
    "birth_df = pd.read_csv(data_folder +'valeurs_mensuelles.csv', sep= ';', index_col= 0, skiprows=2, usecols=[0,1],header=0, names=['PÃ©riode','birth'])\n",
    "\n",
    "# Changing indexes to panda date\n",
    "birth_df.index = pd.to_datetime(birth_df.index)\n",
    "\n",
    "# Putting sales data in log scale as we want\n",
    "birth_df['birth'] = birth_df['birth'].apply(np.log)\n",
    "\n",
    "# Getting an overview\n",
    "birth_df = birth_df.sort_index()\n",
    "birth_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 Google Trend Data\n",
    "### 1.2.1 Find all Google Trend Data categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function definition we will use later for extracting data contained in a nested dictionaries with lists.\n",
    "def extract(dict_in, list_out, list_out2,list_out3 ,list_out4 , parent,i,MinLevel):\n",
    "    '''\n",
    "    Recursive function extracting data contained in a nested dictionaries with lists.\n",
    "    It extract:\n",
    "     - all integers\n",
    "     - entry with key 'name'\n",
    "     - the level (parent/children) of the nested dictionary\n",
    "     - the parent name of the previous dictionary\n",
    "     \n",
    "    The code was adapted from here : https://stackoverflow.com/questions/10569636/how-to-get-all-keysvalues-in-nested-dict-of-list-of-dicts-and-dicts/10569687\n",
    "    \n",
    "    INPUT:\n",
    "        - dict_in: dictionary you want to extract from\n",
    "        - list_out(1-4): list containing all information found by previous recursion (more details in OUTPUT)\n",
    "        - parent:  name of last entry with key 'name' and level equal to Minlevel found by previous recursion\n",
    "        - i: level of previous recursive function\n",
    "        - Min level: Level at where we want to keep track of parent dictionary\n",
    "        \n",
    "    OUTPUT:\n",
    "        - list_out: list containing all integers entry in dict_in\n",
    "        - list_out2: list containing all entry entry with key 'name' in dict_in\n",
    "        - list_out3: list containing all levels of dict_in\n",
    "        - list_out4: list containing all parent name of dict_in\n",
    "        - parent: name of last entry with key 'name' and level equal to Minlevel\n",
    "        - i: level of current recursive function\n",
    "    '''\n",
    "    i=i+1                                             # Add one level to recursive function\n",
    "\n",
    "                                                      # Reverse the dictionary order\n",
    "    rdict_in = dict()                                 # Prepare a new  dictionary\n",
    "    for k in reversed(dict_in):                       # For each entry in reversed ordered dictionary\n",
    "        rdict_in[k] = dict_in[k]                          # Save it in new dictionary\n",
    "    \n",
    "    for key, value in rdict_in.items():               # for all entry in reversed dict_in\n",
    "        if isinstance(value, dict):                       # If value itself is dictionary\n",
    "            extract(value,\n",
    "                    list_out, list_out2,\n",
    "                    list_out3, list_out4,\n",
    "                    parent, i,MinLevel)                       # Then do recursion and input this dictionary in dict_in\n",
    "        elif isinstance(value, list):                     # Else if this value is a list\n",
    "            for key2 in value:                                 # Then for each entry in this list\n",
    "                extract(key2,\n",
    "                        list_out, list_out2,\n",
    "                        list_out3,list_out4,\n",
    "                        parent,i,MinLevel)                         # Do recursion and input this entry in dict_in\n",
    "        elif isinstance(value, int):                      # Else if this value is an integer\n",
    "            list_out.append(value)                             # Add the value to list_out\n",
    "        elif key=='name':                                 # Else if this value has key == 'name'\n",
    "            list_out2.append(value)                            # Add this value to list_out2\n",
    "            list_out3.append(i)                                # Add the level of this value in list_out3\n",
    "            if i==MinLevel:                                    # If current level is equal to the level we want to keep track of\n",
    "                parent = value                                     # Then add current value to the parent variable\n",
    "                list_out4.append('nul')                            # Add the value 'nul' as parent of current value\n",
    "            else:                                              # Else\n",
    "                list_out4.append(parent)                           # Add the last parent as parent of current value\n",
    "    return list_out,list_out2,list_out3,list_out4 , parent ,i # Return the two list to have valid recursion\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a trend rquest object with language, timzone offset, number of retry if request fail, time factor to make each retry (wait 0.1s , 0.2s, 0.3s, ...)\n",
    "pytrends = TrendReq(hl='US-US',tz=60, retries=10,backoff_factor=0.1,)\n",
    "\n",
    "# Extract all google trend categories in a nested dictionary\n",
    "categories_dictionary = pytrends.categories()\n",
    "\n",
    "# Initailaze list for extracting data\n",
    "categories_ids =[]\n",
    "categories_names = []\n",
    "level=[]\n",
    "parent =[]\n",
    "# Initialise level, and name for categories with no parents\n",
    "i=0\n",
    "init='nul'\n",
    "# Selecting the level of categroies we want to keep as parent\n",
    "MinLevel = 2\n",
    "# Extracting the Categories in the nested dictionary using recursive function\n",
    "[categories_ids,categories_names,level,parent,init,i] = extract(categories_dictionary,categories_ids,categories_names,level,parent , init,i,MinLevel)\n",
    "\n",
    "# making a dataframe and drooping duplicates categories (ex: category Programmation id: 31 is a sub category of 'Computer Hardware' and 'Computer science')\n",
    "categories_df = pd.DataFrame(zip(categories_ids,categories_names,level,parent),columns=['id','name','level','parent']).sort_values(['id','level'])\n",
    "categories_df=categories_df.drop_duplicates(subset =\"id\")\n",
    "\n",
    "# saving to a csv a getting an overview\n",
    "categories_df.to_csv(data_folder + 'categories.csv')\n",
    "categories_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2.2 Extracting all Google Trend Data for each categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initializing a dataframe for Google Trend Data\n",
    "GTD_df = pd.DataFrame()\n",
    "# for each categories\n",
    "for j,i in enumerate(categories_df['id']):\n",
    "    # build request payload empty key word with france geolocation with the i'th category from 2004-01-01 to 2020-12-31\n",
    "    kw_list = [\"\"]\n",
    "    pytrends.build_payload(kw_list, geo='FR', cat=i , timeframe='2004-01-01 2020-12-31')\n",
    "    \n",
    "    # getting google trend data\n",
    "    temp = pytrends.interest_over_time()\n",
    "    \n",
    "    # if the return is not empty save data (may happen for small categories with not enough data the return is empty\n",
    "    # Ex : category 42 \"jazz\" https://trends.google.com/trends/explore?cat=42&date=all&geo=FR)\n",
    "    if not temp.empty:\n",
    "        GTD_df[i]=temp.iloc[:,0]   \n",
    "    \n",
    "# getting an overview    \n",
    "GTD_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An error is araising because pytrend is not unofficial pseudo API for google trend. Therefore some error are raising and they are not solved yet.<br>\n",
    "As we can read here: https://github.com/GeneralMills/pytrends/issues/413, the error 429 we are obtaining now is often a \"Too many request\" code but this error is arraising for random number of requests and has no definite solution.<br>\n",
    "Therefore, we made the preprocessing in another notebook by running it multiple time and made a full dataframe containing all the request that we will import in the next cells."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing google trend data preprocessed exactly the same in another notebook\n",
    "GTD_df = pd.read_csv(data_folder +'GTD.csv',index_col= 0)\n",
    "GTD_df.index = pd.to_datetime(GTD_df.index)\n",
    "GTD_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Category Selection\n",
    "\n",
    "## 2.0. Mini preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function to standardize data\n",
    "def standardize(data):\n",
    "    mean_x = np.mean(data)\n",
    "    std_x = np.std(data)\n",
    "    x = data\n",
    "    x = x - mean_x\n",
    "    for i in range (len(std_x)):\n",
    "        if std_x[i] == 0:\n",
    "            std_x[i]=1\n",
    "    x = x / std_x\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make columns name to numeric\n",
    "col = pd.to_numeric(GTD_df.columns)\n",
    "\n",
    "# Keeping only the elements of interest and getting an overview\n",
    "categories_df = categories_df[categories_df['id'].isin(col)]\n",
    "\n",
    "# standardize the Google Trend Data\n",
    "GTD_df = standardize(GTD_df)\n",
    "\n",
    "# Remove seasonnality \n",
    "# Make function\n",
    "\n",
    "# Shifting columns to make Auto Regressive model\n",
    "nan = np.empty(6)\n",
    "nan[:] = 0\n",
    "birth_df['birth_6'] =  [*nan , *birth_df.birth[:-6].values] # Moving down 6 rows and putting 0 in the empty space\n",
    "nan = np.empty(12)\n",
    "nan[:] = 0\n",
    "birth_df['birth_12'] =  [*nan , *birth_df.birth[:-12].values] # Moving down 12 rows and putting 0 in the empty space"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.0.0. Rolling window validation\n",
    "\n",
    "Validation de la roling window sur le base model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding several parameters\n",
    "k = 23"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1. By correlation overall\n",
    "\n",
    "### 2.1.1. Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function definition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1.2. Parameter validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1.3. Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2. By correlation with rolling window\n",
    "\n",
    "### 2.2.1 Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function definition\n",
    "def bestFeatureCorrelation(date, k):\n",
    "    '''\n",
    "    date: date at which we want to determine the correlation\n",
    "    k: size of the data we want to check the correlation on (size recommended: identical to the ORLS)\n",
    "    '''    \n",
    "    \n",
    "    #Number of month in which we should look for correlation before choosing the best (size of the rolling ols)\n",
    "    pearson = [] #df in which we store the pearson correlation factor\n",
    "    kendall = [] #df in which we store the kendall correlation factor\n",
    "    spearman = [] #df in which we store the spearman correlation factor\n",
    "    \n",
    "    date = single_date.strftime(\"%Y-%m-%d\")\n",
    "    end_date = datetime.strptime(date, '%Y-%m-%d')  \n",
    "    start_date = end_date - relativedelta(months=+k)\n",
    "\n",
    "    end_date = datetime.strftime(end_date, '%Y-%m-%d')\n",
    "    start_date = datetime.strftime(start_date, '%Y-%m-%d')\n",
    "\n",
    "    temp_df=pd.DataFrame(GTD_df.loc[start_date:end_date], dtype='float') #Taking the time index that are also in the birth_df\n",
    "    birth_temp = pd.DataFrame(birth_df.loc[start_date:end_date], dtype='float')\n",
    "    for i,j in enumerate(categories_df['id']):\n",
    "\n",
    "        if str(j) in temp_df.columns:\n",
    "            #Pearson correlation calculation\n",
    "            pearsonTemp = np.abs(birth_temp.iloc[:,0].corr(temp_df[str(j)],method='pearson'))\n",
    "            pearson.append(pearsonTemp)\n",
    "            #Kendall correlation calculation\n",
    "            kendallTemp = np.abs(birth_temp.iloc[:,0].corr(temp_df[str(j)],method='kendall'))       \n",
    "            kendall.append(kendallTemp)\n",
    "            #Spearman correlation calculation\n",
    "            spearmanTemp = np.abs(birth_temp.iloc[:,0].corr(temp_df[str(j)],method='spearman'))\n",
    "            spearman.append(spearmanTemp)\n",
    "\n",
    "        else:\n",
    "            #if the correlation could not be calculated -> put NaN\n",
    "            pearson.append(np.nan)\n",
    "            kendall.append(np.nan)\n",
    "            spearman.append(np.nan)\n",
    "\n",
    "    #Normalizing our correlation indicators in order to combine them and compare them\n",
    "    pearsonNorm = 100 / np.nanmax(pearson)\n",
    "    categories_df['Pearson'] = np.multiply(pearsonNorm, pearson)\n",
    "    kendallNorm = 100 / np.nanmax(kendall)    \n",
    "    categories_df['Kendall'] = np.multiply(kendallNorm, kendall)\n",
    "    spearmanNorm = 100 / np.nanmax(spearman)\n",
    "    categories_df['Spearman'] = np.multiply(spearmanNorm, spearman)\n",
    "\n",
    "    #Crossing between our correlations to see which feature is the best\n",
    "    cal = pd.DataFrame([categories_df[\"Spearman\"], categories_df[\"Pearson\"], categories_df[\"Kendall\"]]).transpose()\n",
    "    cal = cal.mean(axis=1)\n",
    "    categories_df['Mean'] = cal\n",
    "\n",
    "    #Displaying the 10 best\n",
    "    categories_best = categories_df.sort_values('Mean', ascending=False).iloc[0:20,:].reset_index(drop=True)\n",
    "    return  categories_best\n",
    "\n",
    "def dateRange(start_date, end_date,k):\n",
    "    '''\n",
    "    start_date: start date of the date range\n",
    "    end_date: end date of the date range\n",
    "    '''\n",
    "    for n in range(k, rep):#GTD_df.shape[0]):\n",
    "        yield start_date + relativedelta(months=n)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2.2. Parameter validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2.3. Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Data for correlation\n",
    "#start_date = '2004-01-01' \n",
    "#end_date = '2020-11-01'\n",
    "#k = 18\n",
    "\n",
    "#Date processing\n",
    "start_date = datetime.strptime(start_date, '%Y-%m-%d')  \n",
    "end_date = datetime.strptime(end_date, '%Y-%m-%d')\n",
    "rep = len(pd.date_range(start_date,end_date, freq='M'))\n",
    "\n",
    "#output dataframe for the best parameters\n",
    "best = pd.DataFrame()\n",
    "\n",
    "#Loop in which we find the best hyper parameters with correlation\n",
    "for single_date in dateRange(start_date, end_date, k):\n",
    "    date = single_date.strftime(\"%Y-%m-%d\")\n",
    "    corr = bestFeatureCorrelation(date, k)\n",
    "    best[date]=corr.id[0:10]\n",
    "    if single_date.month == 1:\n",
    "        print(date)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3. By improvement overall\n",
    "\n",
    "### 2.3.1. Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function definition\n",
    "def best_feature_improvement(k,start = '2004-01-01', end = '2020-10-01'):\n",
    "    '''\n",
    "    Input: \n",
    "        -start: start date in format '2004-01-01'\n",
    "        -end: end date in format '2020-10-01'\n",
    "        k: rolling windows size, recommended size : 6\n",
    "    '''\n",
    "\n",
    "\n",
    "    improvement = []\n",
    "\n",
    "\n",
    "    #Checking for each feature\n",
    "    for i in GTD_df.columns:\n",
    "\n",
    "        #Setting the dfs\n",
    "        df = birth_df.copy()\n",
    "        \n",
    "\n",
    "        #Setting the feature of interest\n",
    "        df = df.loc[start:end]\n",
    "        temp_GTD_df = GTD_df.loc[start:end]\n",
    "        df[\"y0\"] = temp_GTD_df[i]\n",
    "        df = df.reset_index(drop=True) #Resetting the index to [0-n] format\n",
    "\n",
    "        #Basic reg\n",
    "        res_base = RollingOLS.from_formula('birth ~ birth_6 + birth_12', data=df, window=k).fit() #We use our rolling windows function\n",
    "        params = pd.DataFrame(res_base.params.shift(periods=1, axis=0)) #we shift the output parameters one row down in order to apply to the next mont (predict)\n",
    "        params.columns = ['a0','a1','a2'] #Changing the parameters' columns names\n",
    "        df = pd.concat([df, params], axis=1) #adding it to our dataframe\n",
    "        df['predict_base'] = df.a0 + df.a1*df.birth_6 + df.a2*df.birth_12 #predicting the values for the next month\n",
    "\n",
    "        #Trend reg with feature of interest\n",
    "        res_trend = RollingOLS.from_formula('birth ~ birth_6 + birth_12 + y0', data=df, window=k).fit()#We use our rolling windows function\n",
    "        params = pd.DataFrame(res_trend.params.shift(periods=1, axis=0)) #we shift the output parameters one row down in order to apply to the next mont (predict)\n",
    "        params.columns = ['b0','b1','b2','b3']#Changing the parameters' columns names\n",
    "        df = pd.concat([df, params], axis=1) #adding it to our dataframe\n",
    "        df['predict_trend'] = df.b0 + df.b1*df.birth_6 + df.b2*df.birth_12 + df.b3 * df.y0   #predicting the values for the next month\n",
    "\n",
    "        #Calculating MAE and Improvement\n",
    "        mae_base = np.mean(abs(df.birth-df.predict_base))*100\n",
    "        mae_trends = np.mean(abs(df.birth-df.predict_trend))*100\n",
    "        improvement_overall = (mae_base-mae_trends)*100 /mae_base\n",
    "        improvement.append(improvement_overall)\n",
    "\n",
    "\n",
    "    #Our df well ordered\n",
    "    categories_best = categories_df.reset_index(drop=True)\n",
    "    categories_best['Improvement'] = pd.DataFrame(improvement)\n",
    "    categories_best = categories_best.sort_values('Improvement', ascending=False)\n",
    "    categories_best = categories_best.reset_index(drop=True)\n",
    "    \n",
    "    return categories_best\n",
    "\n",
    "def make_date_best(best):\n",
    "    temp = pd.DataFrame(index = birth_df.index)\n",
    "    for i in range (number_of_best_cat):\n",
    "        temp[str(\"id{}\".format(best.index[i]))] = np.ones((len(birth_df),1)) * best.id[i]\n",
    "    return temp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3.2. Parameter validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3.3. Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find best feature overall\n",
    "best = best_feature_improvement(k)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.4. By improvement with rolling window\n",
    "\n",
    "### 2.4.1. Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function definition\n",
    "def best_feature_improvement_rolling(months_shift):\n",
    "    columns_name = []\n",
    "    for i in range (number_of_best_cat):\n",
    "        columns_name.append(str(\"id{}\".format(i)))\n",
    "    \n",
    "    #make shift\n",
    "    Date_shifted = birth_df.index.shift(-months_shift, freq ='MS') \n",
    "    Date_shifted_1 = birth_df.index.shift(-1, freq ='MS') \n",
    "    \n",
    "    predict_gtd = pd.DataFrame(dtype='float')\n",
    "    categories_best = pd.DataFrame()\n",
    "    improvements = pd.DataFrame()\n",
    "    #for each date\n",
    "    for i in range(months_shift,len(birth_df)):\n",
    "        #get correct time range\n",
    "        start = Date_shifted[i]\n",
    "        end = Date_shifted_1[i]\n",
    "        #find best categories\n",
    "        categories_best_temp = best_feature_improvement(k,start,end)\n",
    "        #add it to df\n",
    "        predict_gtd = predict_gtd.append(categories_best_temp.id[0:number_of_best_cat].transpose())\n",
    "        categories_best = categories_best.append(categories_best_temp.name[0:number_of_best_cat].transpose())\n",
    "        improvements = improvements.append(categories_best_temp.Improvement[0:number_of_best_cat].transpose())\n",
    "        print(birth_df.index[i])\n",
    "        \n",
    "    \n",
    "    #create dataframe with correct indices and columns name\n",
    "    predict_gtd.index = birth_df.index[months_shift:]\n",
    "    predict_gtd.columns = columns_name\n",
    "    \n",
    "    categories_best.index = birth_df.index[months_shift:]\n",
    "    improvements.index = birth_df.index[months_shift:]\n",
    "    categories_best = pd.merge(categories_best,improvements,left_index = True,right_index = True)\n",
    "    return categories_best"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4.2. Parameter validation\n",
    "#### 2.4.2.1. Months shifting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shift = 1\n",
    "\n",
    "months_shift = k+shift"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.4.2.2. Number of best categories"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "number_of_best_cat =1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4.3. Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best = best_feature_improvement_rolling(months_shift)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.5. Final Algorithm selection\n",
    "\n",
    "### 2.5.1. Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.5.2. Final category selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best = best_feature_improvement_rolling(months_shift)\n",
    "best"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Prediction and visualization\n",
    "\n",
    "## 3.1 Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prediction(date,k,birth_df,GTD,ids):\n",
    "    '''\n",
    "    date: dates at which we want to predict\n",
    "    k: size of the rolling windows\n",
    "    df: birth df\n",
    "    temp_GTD: Google Trends DF\n",
    "    ids.: ids of category\n",
    "    '''\n",
    "    \n",
    "    df = birth_df.copy()\n",
    "    temp_GTD = GTD_df.copy()\n",
    "    \n",
    "    end = datetime.strptime(date, '%Y-%m-%d')  \n",
    "    start = end - relativedelta(months=+k)\n",
    "    end = datetime.strftime(end, '%Y-%m-%d')\n",
    "    start = datetime.strftime(start, '%Y-%m-%d')\n",
    "    \n",
    "    df = df.loc[start:end]\n",
    "    temp_GTD = temp_GTD.loc[start:end]\n",
    "    \n",
    "    #Features selection\n",
    "    formula = str('birth ~ birth_6 + birth_12')\n",
    "    columns_name = ['b0','b1','b2']\n",
    "    for j,i in enumerate(ids):\n",
    "        df[\"y%d\"%j] = temp_GTD.loc[:,str(int(i))]\n",
    "        formula = formula + ' + ' + str(\"y%d\"%j)\n",
    "        columns_name.append(str(\"b%d\"%(j+ 3)))\n",
    "        #GTD_df.loc[:,str(categories_best.id[i])]\n",
    "\n",
    "    index_date = df.index #saving the index for later plotting\n",
    "    df = df.reset_index(drop=True) #Resetting the index to [0-n] format\n",
    "\n",
    "\n",
    "    res_base = RollingOLS.from_formula('birth ~ birth_6 + birth_12', data=df, window=k).fit() #We use our rolling windows function\n",
    "    params = pd.DataFrame(res_base.params.shift(periods=1, axis=0)) #we shift the output parameters one row down in order to apply to the next mont (predict)\n",
    "    params.columns = ['a0','a1','a2'] #Changing the parameters' columns names\n",
    "    df = pd.concat([df, params], axis=1) #adding it to our dataframe\n",
    "    df['predict_base'] = df.a0 + df.a1*df.birth_6 + df.a2*df.birth_12 #predicting the values for the next month\n",
    "\n",
    "    res_trend = RollingOLS.from_formula(formula, data=df, window=k).fit()#We use our rolling windows function\n",
    "    params = pd.DataFrame(res_trend.params.shift(periods=1, axis=0)) #we shift the output parameters one row down in order to apply to the next mont (predict)\n",
    "    params.columns = columns_name#Changing the parameters' columns names\n",
    "    df = pd.concat([df, params], axis=1) #adding it to our dataframe\n",
    "    df['predict_trend'] = df.b0 + df.b1*df.birth_6 + df.b2*df.birth_12 \n",
    "    for j,i in enumerate(ids):\n",
    "        df['predict_trend'] = df['predict_trend'] + params.iloc[:,3+j]*  df.iloc[:,3+j]  #predicting the values for the next month\n",
    "\n",
    "\n",
    "    #add date index again\n",
    "    df.index = index_date\n",
    "\n",
    "    #MAE + Improvement overall calculation between the base fit and base+trend fit\n",
    "    mae_base = np.mean(abs(df.birth-df.predict_base))*100\n",
    "    mae_trends = np.mean(abs(df.birth-df.predict_trend))*100\n",
    "    improvement_overall = (mae_base-mae_trends)*100 /mae_base\n",
    "    return df,improvement_overall\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2 Prediction plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function to show the plot from paper\n",
    "def showPlot(df, improvement_overall):\n",
    "    '''\n",
    "    df: DataFrame with all the parameters to plot (birth; predict_base; predict_trend)\n",
    "    improvement_overall: value of the improvement\n",
    "    '''\n",
    "    \n",
    "    #Defining the overall parameters for the figure\n",
    "    params = {'legend.fontsize': 20,\n",
    "              'legend.handlelength': 3,\n",
    "              'figure.figsize': (15,10),\n",
    "              'axes.labelsize' : 15,\n",
    "              'xtick.labelsize' : 15,\n",
    "              'ytick.labelsize' : 15}\n",
    "    plt.rcParams.update(params) #applying them\n",
    "\n",
    "    #plotting each curve with specific parameters\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.plot(df.birth, 'k', linewidth=2, label='Actual') #Thicker line for the real data\n",
    "    ax.plot(df.predict_base, 'k--', linewidth=1,label='Base') #Doted line for the predicted curve with basic data\n",
    "    ax.plot(df.predict_trend, 'k', linewidth=1, label='Trends') #Classic line for the predicted curve with basic + trend data\n",
    "\n",
    "    #Defining figure title\n",
    "    plt.suptitle('Births in France', fontsize=20)\n",
    "\n",
    "    #Defining (x;y) labels\n",
    "    plt.xlabel('Index')\n",
    "    plt.ylabel('log(mvp)')\n",
    "\n",
    "    #Plotting the legend\n",
    "    plt.legend(loc=\"upper right\")\n",
    "\n",
    "    #Creating the box with the MAE improvements\n",
    "    textstr = '\\n'.join((\n",
    "        r'MAE improvement',\n",
    "        r'Overall = $%.1f$%%' % (improvement_overall, )))\n",
    "    ax.text(0.013, 0.135, textstr, transform=ax.transAxes, fontsize=17.5,\n",
    "            verticalalignment='top', bbox=dict(facecolor='none', edgecolor='black', pad=10))\n",
    "\n",
    "    #Showing the plot\n",
    "    plt.show\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df = pd.DataFrame(index = best.columns)\n",
    "df[\"birth\"]=birth\n",
    "df[\"predict_base\"]=base\n",
    "df[\"predict_trend\"]=trend\n",
    "improvement_overall = np.mean(imp)\n",
    "\n",
    "showPlot(df, improvement_overall)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.3 Visualisation of categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CountFrequency(my_list): \n",
    "  \n",
    "    # Creating an empty dictionary  \n",
    "    freq = {} \n",
    "    for item in my_list: \n",
    "        if (item in freq): \n",
    "            freq[item] += 1\n",
    "        else: \n",
    "            freq[item] = 1\n",
    "    \n",
    "    return freq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:ada] *",
   "language": "python",
   "name": "conda-env-ada-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
